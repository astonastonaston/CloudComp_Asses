21/10/28 23:28:08 INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com/10.26.10.201:10200
Running 1 maps.
Job started: Thu Oct 28 23:28:09 CST 2021
21/10/28 23:28:09 INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com/10.26.10.201:10200
21/10/28 23:28:09 INFO hdfs.DFSClient: Created token for team12: HDFS_DELEGATION_TOKEN owner=team12@BIGDATA, renewer=yarn, realUser=, issueDate=1635435182309, maxDate=1636039982309, sequenceNumber=5119569, masterKeyId=654 on ha-hdfs:cuhkcluster
21/10/28 23:28:09 INFO kms.KMSClientProvider: Getting new token from http://manager.cuhk.com:9292/kms/v1/, renewer:rm/master1.cuhk.com@BIGDATA
21/10/28 23:28:09 INFO kms.KMSClientProvider: New token received: (Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team12, renewer=yarn, realUser=, issueDate=1635435182395, maxDate=1636039982395, sequenceNumber=16455, masterKeyId=265))
21/10/28 23:28:09 INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team12: HDFS_DELEGATION_TOKEN owner=team12@BIGDATA, renewer=yarn, realUser=, issueDate=1635435182309, maxDate=1636039982309, sequenceNumber=5119569, masterKeyId=654)
21/10/28 23:28:09 INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team12, renewer=yarn, realUser=, issueDate=1635435182395, maxDate=1636039982395, sequenceNumber=16455, masterKeyId=265)
21/10/28 23:28:09 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/team12/.staging/job_1633939588974_15404
21/10/28 23:28:09 INFO mapreduce.JobSubmitter: number of splits:1
21/10/28 23:28:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1633939588974_15404
21/10/28 23:28:09 INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team12: HDFS_DELEGATION_TOKEN owner=team12@BIGDATA, renewer=yarn, realUser=, issueDate=1635435182309, maxDate=1636039982309, sequenceNumber=5119569, masterKeyId=654), Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team12, renewer=yarn, realUser=, issueDate=1635435182395, maxDate=1636039982395, sequenceNumber=16455, masterKeyId=265)]
21/10/28 23:28:10 INFO conf.Configuration: found resource resource-types.xml at file:/usr/hdp/3.0.1.0-187/hadoop/etc/hadoop/resource-types.xml
21/10/28 23:28:10 INFO impl.TimelineClientImpl: Timeline service address: manager.cuhk.com:8188
21/10/28 23:28:10 INFO impl.YarnClientImpl: Submitted application application_1633939588974_15404
21/10/28 23:28:10 INFO mapreduce.Job: The url to track the job: http://master1.cuhk.com:8088/proxy/application_1633939588974_15404/
21/10/28 23:28:10 INFO mapreduce.Job: Running job: job_1633939588974_15404
21/10/28 23:28:18 INFO mapreduce.Job: Job job_1633939588974_15404 running in uber mode : false
21/10/28 23:28:18 INFO mapreduce.Job:  map 0% reduce 0%
21/10/28 23:30:56 INFO mapreduce.Job: Task Id : attempt_1633939588974_15404_m_000000_0, Status : FAILED
Error: org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-475321978-10.26.1.59-1576988921417:blk_1077895617_4155319 does not exist.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:5240)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.bumpBlockGenerationStamp(FSNamesystem.java:5312)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:947)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:1096)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy13.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:1038)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.DataStreamer.updateBlockForPipeline(DataStreamer.java:1625)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1502)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)

21/10/28 23:34:17 INFO mapreduce.Job:  map 100% reduce 0%
21/10/28 23:34:17 INFO mapreduce.Job: Job job_1633939588974_15404 completed successfully
21/10/28 23:34:17 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=246661
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=138
		HDFS: Number of bytes written=16291528564
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Job Counters
		Failed map tasks=1
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=1061982
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=353994
		Total vcore-milliseconds taken by all map tasks=353994
		Total megabyte-milliseconds taken by all map tasks=1087469568
	Map-Reduce Framework
		Map input records=1
		Map output records=24414573
		Input split bytes=138
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=3278
		CPU time spent (ms)=253440
		Physical memory (bytes) snapshot=483258368
		Virtual memory (bytes) snapshot=4711911424
		Total committed heap usage (bytes)=574619648
		Peak Map Physical memory (bytes)=483258368
		Peak Map Virtual memory (bytes)=4711911424
	org.apache.hadoop.examples.RandomTextWriter$Counters
		BYTES_WRITTEN=16000000318
		RECORDS_WRITTEN=24414573
	File Input Format Counters
		Bytes Read=0
	File Output Format Counters
		Bytes Written=16291528564
Job ended: Thu Oct 28 23:34:17 CST 2021
The job took 368 seconds.
